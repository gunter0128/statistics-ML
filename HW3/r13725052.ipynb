{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第一題**\n",
    "1000維的影像分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes = 101\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "imagenet_stats = [(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)]\n",
    "\n",
    "valid_tfms = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_stats[0], imagenet_stats[1])\n",
    "])\n",
    "\n",
    "batch_size = 196\n",
    "\n",
    "# 加載數據\n",
    "trainset = datasets.Food101(root='./food101', split=\"train\", download=False, transform=valid_tfms)\n",
    "validset = datasets.Food101(root='./food101', split=\"test\", download=False, transform=valid_tfms)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "validloader = DataLoader(validset, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "\n",
    "# 確認分類數量\n",
    "assert trainset.classes == validset.classes\n",
    "classes = trainset.classes\n",
    "print(\"Number of classes =\", len(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "\n",
    "# 載入 ResNet50 並保留完整結構\n",
    "model = resnet50(weights=\"IMAGENET1K_V2\")\n",
    "model.eval()  # 設置為評估模式\n",
    "\n",
    "# 特徵提取函數\n",
    "def extract_features(loader, model, device):\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():  # 不計算梯度以加速推理\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)  # 輸出 1000 維 logits\n",
    "            features.append(outputs.cpu())\n",
    "            labels.append(targets)\n",
    "    return torch.cat(features), torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled training features shape: (20000, 1000)\n",
      "Sampled training labels shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 提取特徵\n",
    "train_features, train_labels = extract_features(trainloader, model, device)\n",
    "valid_features, valid_labels = extract_features(validloader, model, device)\n",
    "\n",
    "# 隨機選取 20,000 張訓練樣本\n",
    "import random\n",
    "\n",
    "def sample_subset(features, labels, sample_size=20000):\n",
    "    indices = random.sample(range(features.shape[0]), sample_size)\n",
    "    subset_features = features[indices]\n",
    "    subset_labels = labels[indices]\n",
    "    return subset_features, subset_labels\n",
    "\n",
    "train_features_sampled, train_labels_sampled = sample_subset(train_features.numpy(), train_labels.numpy(), 20000)\n",
    "\n",
    "print(\"Sampled training features shape:\", train_features_sampled.shape)\n",
    "print(\"Sampled training labels shape:\", train_labels_sampled.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5598\n",
      "Macro-average F1 Score: 0.5567\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 訓練\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "clf = LogisticRegression(C=0.1, max_iter=1000)\n",
    "clf.fit(train_features_sampled, train_labels_sampled)\n",
    "\n",
    "# 預測測試集\n",
    "preds = clf.predict(valid_features.numpy())\n",
    "\n",
    "# 計算準確率\n",
    "accuracy = accuracy_score(valid_labels.numpy(), preds)\n",
    "print(\"Validation Accuracy: {:.4f}\".format(accuracy))\n",
    "\n",
    "# 計算 Macro-average F1\n",
    "macro_f1 = f1_score(valid_labels.numpy(), preds, average='macro')\n",
    "print(\"Macro-average F1 Score: {:.4f}\".format(macro_f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第二題**\n",
    "2048維的影像辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "\n",
    "# 移動模型到設備\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = resnet50(weights=\"IMAGENET1K_V2\")\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))  # 移除 'fc' 層\n",
    "model = model.to(device)  # 確保模型在 GPU 上\n",
    "model.eval()\n",
    "\n",
    "# 特徵提取函數\n",
    "def extract_features(loader, model, device):\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to(device)  # 確保輸入在 GPU 上\n",
    "            outputs = model(inputs)  # 提取特徵\n",
    "            features.append(outputs.view(outputs.size(0), -1).cpu())  # 展平成 (batch_size, 2048)\n",
    "            labels.append(targets)\n",
    "    return torch.cat(features), torch.cat(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: torch.Size([75750, 2048])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(trainloader, model, device)\n",
    "print(\"Train features shape:\", train_features.shape)  # (20000, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5829\n",
      "Macro-average F1 Score: 0.5797\n"
     ]
    }
   ],
   "source": [
    "# 隨機選取 20,000 張訓練樣本\n",
    "train_features_sampled, train_labels_sampled = sample_subset(train_features.numpy(), train_labels.numpy(), 20000)\n",
    "\n",
    "# Logistic Regression 訓練\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "clf = LogisticRegression(C=0.1, max_iter=1000)\n",
    "clf.fit(train_features_sampled, train_labels_sampled)\n",
    "\n",
    "# 測試集預測與指標計算\n",
    "valid_features, valid_labels = extract_features(validloader, model, device)\n",
    "preds = clf.predict(valid_features.numpy())\n",
    "accuracy = accuracy_score(valid_labels.numpy(), preds)\n",
    "macro_f1 = f1_score(valid_labels.numpy(), preds, average='macro')\n",
    "\n",
    "# 輸出結果\n",
    "print(\"Validation Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Macro-average F1 Score: {:.4f}\".format(macro_f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **比較報告與分析：1000 維特徵 vs. 2048 維特徵**\n",
    "**實驗結果**\n",
    "\n",
    "| 維度      |  Validation Accuracy | Macro-average F1 Score         |\n",
    "|:-----------:|:-------:|:--------------:|\n",
    "| 1000      | 0.5598    | 0.5567     |\n",
    "| 2048      | 0.5829    | 0.5797     |\n",
    "\n",
    "\n",
    "從結果可以觀察到：\n",
    "使用 2048 維特徵 的 Validation Accuracy 和 Macro-average F1 Score 都高於使用 1000 維特徵的情況。\n",
    "差異並不算非常大，但仍然具有一定的提升。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **可能的原因分析**\n",
    "\n",
    "**特徵維度的影響**\n",
    "\n",
    "1. 2048 維特徵 是 ResNet50 模型中更靠近輸入的層輸出，保留了更多底層和中層的特徵，可能包含更豐富的結構化細節，例如邊緣、紋理等。\n",
    "1000 維特徵 是 ResNet50 的最後輸出，主要是針對 ImageNet 類別的分類調優過的特徵，可能對 Food101 的泛化能力稍弱。\n",
    "分類器的適應能力\n",
    "\n",
    "2. Logistic Regression 能夠處理高維數據，但在 1000 維特徵 的情況下，模型可能略微欠擬合（underfitting）。\n",
    "2048 維特徵 提供了更多的數據變化空間，分類器能更好地學習到不同類別的分佈。\n",
    "數據適配性\n",
    "\n",
    "3. ResNet50 的 1000 維特徵是針對 ImageNet 訓練的，可能與 Food101 的特徵分佈存在一定偏差。\n",
    "2048 維特徵 則更通用，未經過針對性調整，因此在 Food101 上可能更適合。\n",
    "過擬合的可能性\n",
    "\n",
    "4. 使用 2048 維特徵可能會有更多的特徵冗餘，但目前的樣本數量（20,000 張圖片）對 Logistic Regression 來說，仍然足夠避免過擬合的問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **結論與建議**\n",
    "\n",
    "**2048 維特徵效果更好:**\n",
    "\n",
    "1. 在本次實驗中，2048 維特徵的分類性能略高於 1000 維特徵。\n",
    "高維特徵保留了更多的結構化信息，對 Food101 這樣的多類別數據集可能更為適合。\n",
    "應用場景的選擇:\n",
    "\n",
    "2. 如果計算資源有限，使用 1000 維特徵可以減少存儲和計算成本，同時保持接近的分類性能。\n",
    "如果對分類精度要求較高，尤其是對 Macro-average F1 的要求更高，可以選擇 2048 維特徵。\n",
    "未來優化方向:\n",
    "\n",
    "3. 嘗試其他分類器（例如 SVM 或神經網路）進一步提升分類性能。\n",
    "探討對 ResNet50 特徵進行微調（Fine-tuning），可能進一步提升 1000 維特徵的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第三題**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.環境準備\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# 訓練數據的增強\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # 隨機裁剪\n",
    "    transforms.RandomHorizontalFlip(),  # 隨機水平翻轉\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 測試數據的處理\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop(224),  # 中心裁剪\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#數據加載\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 訓練集和測試集加載\n",
    "train_dataset = ImageFolder(root='./food101/food-101/images', transform=train_transforms)\n",
    "test_dataset = ImageFolder(root='./food101/food-101/images', transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.模型定義\n",
    "\n",
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn as nn\n",
    "\n",
    "# 載入預訓練模型\n",
    "model = resnet50(weights=\"IMAGENET1K_V2\")\n",
    "num_ftrs = model.fc.in_features  # 原始 fc 層的輸入維度\n",
    "model.fc = nn.Linear(num_ftrs, 101)  # 替換為 101 類別的全連接層\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全模型調整\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只調整 fc 層\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.訓練與驗證過程\n",
    "#損失函數與優化器\n",
    "#使用交叉熵損失和 Adam 優化器進行訓練：\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定義損失函數與優化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "# 根據題目要求，設置 Early Stopping（若驗證集表現 5 個 epoch 無提升則停止訓練）：\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None or score > self.best_score:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練函數\n",
    "\n",
    "def train_and_validate(model, train_loader, test_loader, criterion, optimizer, device, max_epochs=100):\n",
    "    model.to(device)\n",
    "    early_stopping = EarlyStopping(patience=5)\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    val_f1_history = []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "        val_acc = correct / total\n",
    "        val_f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc)\n",
    "        val_f1_history.append(val_f1)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        if early_stopping(val_loss):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    return train_loss_history, val_loss_history, train_acc_history, val_acc_history, val_f1_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.4730, Val Loss: 2.0877, Val Acc: 0.4938, Val F1: 0.4861\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m      5\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 訓練只調整 fc 層\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n",
      "Cell \u001b[1;32mIn[25], line 21\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(model, train_loader, test_loader, criterion, optimizer, device, max_epochs)\u001b[0m\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 21\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 4.執行兩種 Fine-Tuning 策略\n",
    "\n",
    "# 訓練全模型\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "train_and_validate(model, train_loader, test_loader, criterion, optimizer, device)\n",
    "\n",
    "# 訓練只調整 fc 層\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "train_and_validate(model, train_loader, test_loader, criterion, optimizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.可視化訓練曲線\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 畫圖函數\n",
    "def plot_metrics(train_history, val_history, metric_name):\n",
    "    plt.plot(train_history, label=f'Train {metric_name}')\n",
    "    plt.plot(val_history, label=f'Validation {metric_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    plt.title(f'{metric_name} over Epochs')\n",
    "    plt.show()\n",
    "\n",
    "# 繪製曲線\n",
    "plot_metrics(train_loss_history, val_loss_history, 'Loss')\n",
    "plot_metrics(train_acc_history, val_acc_history, 'Accuracy')\n",
    "plot_metrics(val_f1_history, val_f1_history, 'Macro F1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
